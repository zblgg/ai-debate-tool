#!/usr/bin/env python3
"""
å¤šAIè¾©è®ºï¼ˆå¸¦æ¨¡å‹fallbackï¼‰
"""

import os
import asyncio
import aiohttp
import ssl
import certifi
from datetime import datetime
from pathlib import Path

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "")
BASE_URL = "https://openrouter.ai/api/v1"

# æ¨¡å‹fallbackåˆ—è¡¨
CLAUDE_MODELS = [
    "anthropic/claude-3.5-sonnet",
]

GPT_MODELS = [
    "openai/gpt-4o",
    "openai/gpt-4o-mini",
    "openai/gpt-4-turbo",
]

GEMINI_MODELS = [
    "google/gemini-2.0-flash-001",
    "google/gemini-pro",
]


async def call_with_fallback(session, models: list, prompt: str, name: str) -> str:
    """å°è¯•å¤šä¸ªæ¨¡å‹ç›´åˆ°æˆåŠŸ"""
    for model in models:
        try:
            print(f"   å°è¯• {name}: {model}...")
            result = await call_openrouter(session, model, prompt)
            if not result.startswith("[") and len(result) > 100:
                print(f"   âœ… {name} æˆåŠŸ")
                return result
            else:
                print(f"   âš ï¸ {model} è¿”å›å¼‚å¸¸ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
        except Exception as e:
            print(f"   âŒ {model} å¤±è´¥: {e}")
    return f"[{name}æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†]"


async def call_openrouter(session, model: str, prompt: str) -> str:
    """è°ƒç”¨OpenRouter API"""
    url = f"{BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 4096,
        "temperature": 0.7
    }

    async with session.post(url, headers=headers, json=data, timeout=aiohttp.ClientTimeout(total=120)) as resp:
        if resp.status == 200:
            result = await resp.json()
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
        error = await resp.text()
        return f"[APIé”™è¯¯ {resp.status}] {error[:200]}"


ORIGINAL_PROMPT = """è¯·è®¤çœŸåˆ†æä»¥ä¸‹é—®é¢˜ï¼Œç»™å‡ºä½ çš„æ·±åº¦æ€è€ƒï¼š

{question}

è¦æ±‚ï¼š
1. ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘ä¸¥å¯†
2. ç»“åˆå®é™…æ¡ˆä¾‹
3. ç»™å‡ºå…·ä½“å¯æ‰§è¡Œçš„å»ºè®®
4. æŒ‡å‡ºæ½œåœ¨çš„é£é™©å’ŒçŸ›ç›¾ç‚¹
"""

CRITIQUE_PROMPT = """ä½ æ˜¯{current_ai}ã€‚ä½ åˆšæ‰å¯¹ä»¥ä¸‹é—®é¢˜ç»™å‡ºäº†å›ç­”ï¼š

ã€åŸå§‹é—®é¢˜ã€‘
{question}

ã€ä½ çš„å›ç­”ã€‘
{my_answer}

ç°åœ¨ï¼Œå¦å¤–ä¸¤ä¸ªAIä¹Ÿç»™å‡ºäº†ä»–ä»¬çš„å›ç­”ï¼š

ã€{ai_b}çš„å›ç­”ã€‘
{answer_b}

ã€{ai_c}çš„å›ç­”ã€‘
{answer_c}

---

è¯·å®šå‘æ‰¹è¯„å¦å¤–ä¸¤ä¸ªå›ç­”ä¸­çš„è–„å¼±ç‚¹ï¼ŒåŒæ—¶æ‰¿è®¤ä»–ä»¬æ¯”ä½ æ›´å¥½çš„åœ°æ–¹ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚

è¦æ±‚ï¼š
1. æŒ‡å‡ºå…·ä½“çš„é€»è¾‘æ¼æ´æˆ–ç›²ç‚¹
2. æ‰¿è®¤å¯¹æ–¹çš„ä¼˜åŠ¿ï¼ˆå¦‚æœæœ‰ï¼‰
3. åŸºäºæ‰¹è¯„ä¿®æ­£è‡ªå·±çš„è§‚ç‚¹
4. æ€»å­—æ•°ä¸è¶…è¿‡500å­—
"""

JUDGE_PROMPT = """ã€åŸå§‹é—®é¢˜ã€‘
{question}

===== ä¸‰ä¸ªAIçš„å›ç­” =====

ã€Claudeçš„å›ç­”ã€‘
{claude_answer}

ã€GPTçš„å›ç­”ã€‘
{gpt_answer}

ã€Geminiçš„å›ç­”ã€‘
{gemini_answer}

===== ä¸‰æ–¹äº’æ‰¹ =====

ã€Claudeçš„æ‰¹è¯„ã€‘
{claude_critique}

ã€GPTçš„æ‰¹è¯„ã€‘
{gpt_critique}

ã€Geminiçš„æ‰¹è¯„ã€‘
{gemini_critique}

===== ä½ çš„ä»»åŠ¡ =====

ä½œä¸ºæœ€ç»ˆè£åˆ¤ï¼Œè¯·ï¼š
1. è¯„ä¼°ä¸‰æ–¹è§‚ç‚¹çš„ä¼˜åŠ£
2. æŒ‡å‡ºå„è‡ªçš„ç›²ç‚¹
3. ç»¼åˆç»™å‡ºæœ€ç»ˆç»“è®º
4. ç»™å‡ºå…·ä½“å¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®

è¦æ±‚ï¼šä¸è¦å’Œç¨€æ³¥ï¼Œè¦æœ‰æ˜ç¡®çš„åˆ¤æ–­ã€‚
"""


async def run_debate(question: str):
    """æ‰§è¡Œä¸‰AIè¾©è®º"""

    print("=" * 70)
    print("ğŸ”¥ ä¸‰AIè¾©è®ºåˆ†æ")
    print("=" * 70)
    print(f"\né—®é¢˜: {question[:100]}...\n")

    ssl_context = ssl.create_default_context(cafile=certifi.where())
    connector = aiohttp.TCPConnector(ssl=ssl_context)

    async with aiohttp.ClientSession(connector=connector) as session:

        # === é˜¶æ®µä¸€ï¼šåŸå§‹å›ç­” ===
        print("\nğŸ“ é˜¶æ®µä¸€ï¼šæ”¶é›†åŸå§‹å›ç­”")
        print("-" * 50)

        original_prompt = ORIGINAL_PROMPT.format(question=question)

        claude_task = call_with_fallback(session, CLAUDE_MODELS, original_prompt, "Claude")
        gpt_task = call_with_fallback(session, GPT_MODELS, original_prompt, "GPT")
        gemini_task = call_with_fallback(session, GEMINI_MODELS, original_prompt, "Gemini")

        claude_answer, gpt_answer, gemini_answer = await asyncio.gather(
            claude_task, gpt_task, gemini_task
        )

        # === é˜¶æ®µäºŒï¼šäº’æ‰¹ ===
        print("\nğŸ”¥ é˜¶æ®µäºŒï¼šäº’ç›¸æ‰¹è¯„")
        print("-" * 50)

        claude_critique_prompt = CRITIQUE_PROMPT.format(
            current_ai="Claude", question=question, my_answer=claude_answer,
            ai_b="GPT", answer_b=gpt_answer,
            ai_c="Gemini", answer_c=gemini_answer
        )
        gpt_critique_prompt = CRITIQUE_PROMPT.format(
            current_ai="GPT", question=question, my_answer=gpt_answer,
            ai_b="Claude", answer_b=claude_answer,
            ai_c="Gemini", answer_c=gemini_answer
        )
        gemini_critique_prompt = CRITIQUE_PROMPT.format(
            current_ai="Gemini", question=question, my_answer=gemini_answer,
            ai_b="Claude", answer_b=claude_answer,
            ai_c="GPT", answer_c=gpt_answer
        )

        claude_critique, gpt_critique, gemini_critique = await asyncio.gather(
            call_with_fallback(session, CLAUDE_MODELS, claude_critique_prompt, "Claude"),
            call_with_fallback(session, GPT_MODELS, gpt_critique_prompt, "GPT"),
            call_with_fallback(session, GEMINI_MODELS, gemini_critique_prompt, "Gemini")
        )

        # === é˜¶æ®µä¸‰ï¼šæœ€ç»ˆè£åˆ¤ ===
        print("\nâš–ï¸ é˜¶æ®µä¸‰ï¼šæœ€ç»ˆè£åˆ¤")
        print("-" * 50)

        judge_prompt = JUDGE_PROMPT.format(
            question=question,
            claude_answer=claude_answer, gpt_answer=gpt_answer, gemini_answer=gemini_answer,
            claude_critique=claude_critique, gpt_critique=gpt_critique, gemini_critique=gemini_critique
        )

        final_judgment = await call_with_fallback(session, CLAUDE_MODELS, judge_prompt, "è£åˆ¤")

    # ç”ŸæˆæŠ¥å‘Š
    report = f"""# ä¸‰AIè¾©è®ºåˆ†ææŠ¥å‘Š

**é—®é¢˜**: {question}

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}

---

## ç¬¬ä¸€è½®ï¼šåŸå§‹å›ç­”

### Claude
{claude_answer}

---

### GPT
{gpt_answer}

---

### Gemini
{gemini_answer}

---

## ç¬¬äºŒè½®ï¼šäº’ç›¸æ‰¹è¯„

### Claudeçš„æ‰¹è¯„
{claude_critique}

---

### GPTçš„æ‰¹è¯„
{gpt_critique}

---

### Geminiçš„æ‰¹è¯„
{gemini_critique}

---

## æœ€ç»ˆè£åˆ¤ç»“è®º

{final_judgment}
"""

    # ä¿å­˜
    report_dir = Path(__file__).parent
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = report_dir / f"{timestamp}_æ‹›è˜ç­–ç•¥åˆ†æ.md"
    report_path.write_text(report, encoding="utf-8")

    print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    print("\n" + "=" * 70)
    print("æœ€ç»ˆè£åˆ¤ç»“è®º")
    print("=" * 70)
    print(final_judgment)

    return report


async def main():
    question = """
æˆ‘æ˜¯ä¸€å®¶ç«é”…è¿é”åº—çš„è€æ¿ï¼Œæ­£åœ¨æ¨è¿›"åˆä¼™äººè£‚å˜è®¡åˆ’"â€”â€”æŠŠä¼˜ç§€åº—é•¿åŸ¹å…»æˆåˆä¼™äººï¼Œè®©ä»–ä»¬å»å¼€æ–°åº—ã€‚

ç°åœ¨é‡åˆ°ä¸€ä¸ªæ‹›è˜å›°å¢ƒï¼Œè¯·å¸®æˆ‘æ·±åº¦åˆ†æï¼š

ã€æ ¸å¿ƒçŸ›ç›¾ã€‘
1. æˆ‘æƒ³æ‹›"æ²¡æœ‰å…¶ä»–é€‰æ‹©ã€ä¼šå…¨åŠ›ä»¥èµ´"çš„äºº
   - æ¯”å¦‚äºŒæœ¬å­¦å†ã€æ²¡æœ‰å¤§å‚å…‰ç¯
   - è¿™æ¡è·¯å¯¹ä»–ä»¬æ¥è¯´æ˜¯æœ€å¥½çš„æœºä¼šï¼Œæ‰€ä»¥ä¼šæ‹¼å‘½
   - ä½†è¿™æ ·çš„äººå¾€å¾€è§†é‡æœ‰é™ï¼Œå¯èƒ½åªèƒ½åšæ‰§è¡Œ

2. ä½†æˆ‘éœ€è¦ä»–ä»¬æœªæ¥èƒ½"å¤åˆ¶è‡ªå·±"
   - ä¸åªæ˜¯å•åº—åº—é•¿ï¼Œè€Œæ˜¯èƒ½åŸ¹å…»å‡ºä¸‹ä¸€ä¸ªåº—é•¿
   - éœ€è¦æœ‰å…¨å±€æ€ç»´ã€èƒ½å¸¦å›¢é˜Ÿã€èƒ½ä¼ æˆæ–¹æ³•è®º
   - è¿™ä¼¼ä¹éœ€è¦æ›´é«˜çš„è®¤çŸ¥èƒ½åŠ›

ã€æˆ‘çš„å›°æƒ‘ã€‘
- è¿™ä¸¤ä¸ªè¦æ±‚æ˜¯å¦çŸ›ç›¾ï¼Ÿ
- å¦‚ä½•åœ¨æ‹›è˜é˜¶æ®µå°±è¯†åˆ«å‡º"æœ‰æ½œåŠ›æˆé•¿ä¸ºèƒ½å¤åˆ¶ä»–äººçš„äºº"ï¼Ÿ
- æœ‰æ²¡æœ‰å…·ä½“çš„é¢è¯•é—®é¢˜æˆ–æµ‹è¯•æ–¹æ³•ï¼Ÿ
- å¦‚ä½•è®¾è®¡åŸ¹å…»è·¯å¾„ï¼Œè®©"å…¨åŠ›ä»¥èµ´å‹"çš„äººä¹Ÿèƒ½æˆé•¿ä¸º"èƒ½å¸¦å›¢é˜Ÿå‹"ï¼Ÿ

ã€èƒŒæ™¯ä¿¡æ¯ã€‘
- é¤é¥®è¡Œä¸šï¼Œç«é”…è¿é”
- ç›®æ ‡äººç¾¤ï¼š25-35å²ï¼Œæœ‰ä¸€å®šé¤é¥®ç»éªŒ
- æä¾›çš„æ˜¯"åº—é•¿â†’åˆä¼™äºº"çš„æˆé•¿è·¯å¾„
- æ„¿æ„èŠ±6-12ä¸ªæœˆåŸ¹å…»

è¯·ç»™å‡ºç³»ç»Ÿæ€§çš„åˆ†æå’Œå¯æ‰§è¡Œçš„å»ºè®®ã€‚
"""

    await run_debate(question)


if __name__ == "__main__":
    asyncio.run(main())
