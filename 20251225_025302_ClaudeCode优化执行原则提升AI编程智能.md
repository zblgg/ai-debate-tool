# 多AI互批分析报告

**生成时间**: 2025-12-25T02:50:41.573995

**使用模型**: 
- Claude: `anthropic/claude-4.5-opus-20251124`
- OpenAI: `openai/gpt-5.2-thinking`
- Gemini: `google/gemini-3-pro-preview`

---

## 原始问题

我在使用 Claude Code（一个 AI 编程助手 CLI 工具）。我需要在项目的 CLAUDE.md 配置文件中添加一个「执行原则」章节，目的是让 Claude Code 在执行任务时更智能，而不是盲目执行然后频繁报错。

具体问题：Claude Code 有时会明知会失败却反复尝试（比如读取超大 PDF 文件），或者不分析任务就直接执行命令导致卡死。

请分析：
1. 应该在 CLAUDE.md 中写入哪些「执行原则」来指导 AI 的行为？
2. 如何写得简洁有效（不超过 50 行）？
3. 如何平衡 AI 的主动性和不越界？

请给出具体的 markdown 内容建议。

---

## 第一轮：原始回答

### Claude 的回答

# Claude Code 执行原则配置分析与建议

## 问题诊断

根据您描述的问题和搜索结果中的最佳实践，Claude Code 的"盲目执行"主要源于：

1. **缺乏预判机制** - 没有在执行前评估任务可行性
2. **缺乏失败学习** - 重复尝试已知会失败的操作
3. **缺乏资源意识** - 不考虑文件大小、命令耗时等限制

根据 [claude-cn.org](https://www.claude-cn.org/claude-code-docs-zh/configuration/settings) 的官方文档，CLAUDE.md 是 Claude 启动时自动加载的"项目说明书"，非常适合放置执行原则。

---

## 推荐的「执行原则」配置

```markdown
## 执行原则

### 1. 三思后行（Think Before Act）
- 执行任何命令前，先评估：预期结果是什么？可能的失败点？
- 对于文件操作，先检查文件大小和类型（超过 10MB 的文件需谨慎处理）
- 对于耗时命令，预估执行时间，超过 30 秒的操作需告知用户

### 2. 快速失败，不重蹈覆辙（Fail Fast, Learn Fast）
- 同一操作失败 2 次后，停止尝试并分析根因
- 遇到权限、资源、格式错误时，立即报告而非反复重试
- 记住本次会话中已失败的路径，避免重复

### 3. 分步验证（Incremental Verification）
- 复杂任务拆解为小步骤，每步验证后再继续
- 修改代码后立即运行相关测试或类型检查
- 不确定时，先用只读操作（如 ls、cat、head）探查

### 4. 主动沟通边界（Communicate Boundaries）
- 遇到以下情况必须先询问用户：
  - 操作可能影响超过 5 个文件
  - 需要执行可能长时间运行的命令
  - 任务目标模糊或有多种理解方式
- 发现潜在风险时，说明风险再执行

### 5. 资源感知（Resource Awareness）
- 避免：读取二进制文件、超大日志、压缩包内容
- 避免：无限循环的 watch 命令、交互式命令（如 vim、less）
- 对于大文件，优先使用 head、tail、grep 等部分读取
```

---

## 设计原则说明

### 为什么这样写？

| 原则 | 解决的问题 | 参考来源 |
|------|-----------|---------|
| 三思后行 | 防止盲目执行导致的无效尝试 | [xugj520.cn](https://www.xugj520.cn/archives/claude-code-best-practices.html) 提到的"四阶段黄金流程" |
| 快速失败 | 防止反复重试已知失败操作 | 您描述的 PDF 读取问题 |
| 分步验证 | 防止大改动后才发现问题 | 官方推荐的测试驱动开发流程 |
| 主动沟通 | 平衡主动性与不越界 | [claudecode101.com](https://claudecode101.com/zh/tutorial/configuration/claude-md) 建议的用户确认机制 |
| 资源感知 | 防止卡死和超时 | 您描述的命令卡死问题 |

### 简洁性考量

- **总计约 30 行**，远低于 50 行限制
- 使用**动词开头**的祈使句，直接指导行为
- 用**具体数字**（10MB、5个文件、30秒）代替模糊描述
- 每个原则都有**可操作的检查点**

---

## 平衡主动性与边界的策略

```
┌─────────────────────────────────────────────────────────┐
│                    主动性光谱                            │
├──────────┬──────────────────────┬───────────────────────┤
│  高主动   │      适度主动         │      需确认           │
├──────────┼──────────────────────┼───────────────────────┤
│ • 读取文件 │ • 修改单个文件        │ • 批量修改文件        │
│ • 搜索代码 │ • 运行测试           │ • 执行部署命令        │
│ • 分析结构 │ • 格式化代码         │ • 删除文件            │
│ • 生成方案 │ • 创建新文件         │ • 修改配置文件        │
└──────────┴──────────────────────┴───────────────────────┘
```

**关键原则**：只读操作可主动，写入操作需谨慎，破坏性操作必确认。

---

## 潜在风险与注意事项

### ⚠️ 风险点

1. **过度保守** - 原则太严可能导致 AI 频繁询问，降低效率
   - *缓解*：明确列出"可主动执行"的操作清单

2. **规则冲突** - CLAUDE.md 中其他内容可能与执行原则矛盾
   - *缓解*：将执行原则放在文件开头，优先级更高

3. **上下文遗忘** - 长会话中 AI 可能"忘记"这些原则
   - *缓解*：关键原则用 **加粗** 或 `代码块` 强调

### ✅ 最佳实践

1. **配合 settings.json 使用** - 将高风险操作加入权限确认列表
   ```json
   {
     "permissions": {
       "ask": ["Bash(rm:*)", "Bash(git push:*)"]
     }
   }
   ```

2. **定期迭代** - 根据实际使用中遇到的问题，持续补充原则

3. **使用 /clear 命令** - 当 AI 行为异常时，清空上下文重新开始

---

## 完整配置示例（可直接复制）

```markdown
# 项目配置

## 执行原则（优先级最高）

**核心理念：宁可多问一句，不要盲目执行后报错**

### 必须遵守
1. **预判优先**：执行前评估可行性，大文件(>10MB)先用 head/tail 探查
2. **失败即停**：同一操作失败 2 次后，分析原因而非继续重试
3. **分步执行**：复杂任务拆解，每步验证后再继续
4. **边界清晰**：批量修改、长时间命令、模糊需求 → 先询问用户

### 禁止操作
- 读取二进制文件、超大日志、压缩包内容
- 执行交互式命令（vim、less、htop）
- 无 timeout 的 watch/tail -f 命令

---

## 项目信息
（以下填写您的项目具体信息）
```

这个配置将执行原则置于最高优先级，同时保持了简洁性和可操作性。

---

### Gemini 的回答

针对你在使用 Claude Code 时遇到的“盲目执行”和“死循环报错”问题，这通常是因为 AI 缺乏对**环境上下文的预判**和**失败后的反思机制**。

`CLAUDE.md` 是 Claude Code 的“系统级指令”注入点，通过在这里定义“执行原则（Operational Principles）”，相当于给 AI 装上了一套“行为准则”和“刹车片”。

以下是基于官方文档和最佳实践的分析与建议。

### 一、 核心原则分析：AI 到底缺什么？

要解决你提到的问题，我们需要在 `CLAUDE.md` 中补全以下三个维度的逻辑：

1.  **侦查优先（Look before you leap）**：
    *   **痛点**：直接读取 50MB 的 PDF 或日志文件导致上下文溢出或卡死。
    *   **原则**：在读取文件前，**必须**先检查文件类型和大小。对于非文本或大文件，只读元数据或头部。

2.  **验证依赖（Verify before assume）**：
    *   **痛点**：直接运行 `npm run xxx` 或引用库，结果环境里根本没装，导致报错。
    *   **原则**：在执行命令或编写代码前，先检查 `package.json`、`requirements.txt` 或当前目录结构。

3.  **反思循环（Think before retry）**：
    *   **痛点**：命令报错后，AI 往往会尝试用一模一样的命令重试，或者盲目修改参数。
    *   **原则**：遇到错误必须停止执行，先读取错误日志（Logs），分析原因，提出新方案，严禁盲目重试。

### 二、 具体的 Markdown 内容建议（< 50 行）

请将以下内容添加到你的项目根目录 `CLAUDE.md` 文件中。这段内容经过精简，使用了 Claude 能敏锐识别的关键词（如 **MUST**, **NEVER**）。

```markdown
## ⚡️ 执行原则 (Execution Principles)

**你必须严格遵守以下操作规范，以确保高效且安全：**

### 1. 🔍 信息获取与文件操作
- **先侦查后读取**：在读取文件内容（`FileRead`）前，**必须**先使用 `ls -lh` 确认文件大小。
- **大文件限制**：**严禁**直接读取超过 **500KB** 的文件或 PDF/二进制文件。对于大文件，仅使用 `head`、`tail` 或 `grep` 读取关键片段。
- **依赖检查**：在使用任何库或运行脚本前，先检查配置（如 `package.json`）以确认其存在。

### 2. 🛡️ 命令执行安全
- **禁止交互式命令**：**严禁**运行需要用户输入的命令（如 `top`, `vim`, `git rebase -i`），除非使用无头模式标志。
- **超时意识**：对于可能耗时的操作（如构建、下载），应预判时间并告知用户，避免系统卡死。
- **不可逆操作**：执行删除（`rm`）、覆盖写入或破坏性 Git 操作前，**必须**先陈述理由并请求确认。

### 3. 🧠 错误处理与反思
- **拒绝盲目重试**：如果命令执行失败，**禁止**立即重试相同的命令。
- **错误分析流程**：
  1. 读取并分析错误日志（Logs）。
  2. 检查环境上下文（路径、权限、版本）。
  3. 提出基于分析的修复方案。
- **止损机制**：同一任务连续失败 **3次** 后，必须停止并向用户寻求指导。

### 4. 🚀 编码规范
- **最小修改**：只修改必要的部分，保持原有代码风格（命名、注释）。
- **类型安全**：在编写代码时，优先考虑类型检查（TypeScript/MyPy）以减少运行时错误。
```

### 三、 如何平衡 AI 的主动性与不越界？

在配置 `CLAUDE.md` 时，过于严格的限制会导致 AI 变得“懒惰”（什么都要问你），而过于宽松则会导致“失控”。以下是平衡策略：

#### 1. 区分“只读”与“写入”
*   **主动性领域（只读）**：鼓励 AI 主动进行侦查。
    *   *Prompt 暗示*：“你可以自由使用 `ls`, `grep`, `find` 来探索项目结构，无需请求许可。”
*   **边界领域（写入/执行）**：限制 AI 的盲目行动。
    *   *Prompt 暗示*：“在执行修改文件或运行 Shell 命令前，简要说明你的计划。”

#### 2. 设定“停止阈值”
AI 最可怕的是陷入死循环。在上面的配置中，我加入了 **“同一任务连续失败 3 次后，必须停止”** 的规则。这给了 AI 尝试修复的机会（体现主动性），但设置了底线（防止越界和资源浪费）。

#### 3. 利用 `/config` 配合 `CLAUDE.md`
除了 `CLAUDE.md` 的软性约束，建议在 CLI 中配合硬性设置（参考 [claudecode101.com](https://claudecode101.com/zh/tutorial/configuration/claude-md) 和 [claude-cn.org](https://www.claude-cn.org/claude-code-docs-zh/configuration/settings)）：

*   **权限白名单**：对于 `ls`, `cat`, `grep` 等无害命令，可以将其加入 `Allowed Tools`，让 AI 自动执行，无需你每次按 `y` 确认。
*   **敏感文件屏蔽**：在 `settings.json` 中配置 `ignorePatterns` 或 `deny` 权限，物理屏蔽 `.env` 或 `data/*.pdf`，这样 AI 即使想读也读不了。

### 四、 潜在风险与注意事项

1.  **Token 消耗**：`CLAUDE.md` 的内容会包含在每一次对话的 System Prompt 中。虽然 50 行不算多，但如果项目非常庞大，建议定期清理 `CLAUDE.md` 中不必要的历史记录或过时的命令说明，保持精简。
2.  **指令冲突**：Claude Code 自身内置了庞大的 System Prompt（如 [Gemini-CLI 提示词分析](https://m.aitntnews.com/newDetail.html?newId=15556) 中提到的），你的 `CLAUDE.md` 是作为补充存在的。如果发现 AI 不听话，尝试使用更强烈的动词（如 **MUST**, **CRITICAL**）并加粗。
3.  **上下文遗忘**：如果对话过长，AI 可能会“忘记”部分 `CLAUDE.md` 的规则。养成习惯，在开始复杂任务前，使用 `/compact` 命令压缩上下文，或者重新提醒它：“请复习执行原则”。

---

### ChatGPT 的回答

[API错误 400] {"error":{"message":"openai/gpt-5.2-thinking is not a valid model ID","code":400},"user_id":"user_36jVVLYO4xMpjfEEy5jC8GINIDi"}

---

## 第二轮：定向互批

### Claude 对其他AI的批评

## 任务A：攻击

* **对Gemini的攻击**：
"**严禁**直接读取超过 **500KB** 的文件" → **隐含假设不成立**：500KB过于严苛，一个普通React组件文件就可能超过此限制，会导致AI频繁拒绝正常操作。

* **对ChatGPT的攻击**：
"[API错误 400]" → **事实错误**：未提供任何有效回答，无法完成用户任务。

---

## 任务B：承认优势

* Gemini在**"禁止交互式命令"具体列举**这一点上比我更好，因为它明确列出了`top`, `vim`, `git rebase -i`等具体命令，比我笼统说"交互式命令"更具可操作性。

* Gemini在**"利用/config配合CLAUDE.md"**这一点上比我更好，因为它明确建议用`ignorePatterns`物理屏蔽敏感文件，这是硬性防护，比我的软性原则更可靠。

---

## 任务C：自我修正

**需要修正**：

1. **补充具体禁止命令清单**：在"禁止操作"中增加`top`, `vim`, `less`, `git rebase -i`等具体命令名，而非仅说"交互式命令"。

2. **增加硬性配合建议**：在配置示例后补充`settings.json`的`deny`规则用于物理屏蔽大文件/敏感文件，形成软硬结合的防护。

**原始立场依然成立**：我的10MB阈值比Gemini的500KB更合理，避免过度限制正常开发；我的"失败2次即停"比Gemini的"3次"更保守，更符合用户"避免频繁报错"的诉求。

---

### Gemini 对其他AI的批评

### 任务A：攻击

*   **对Claude的攻击**：[预估执行时间，超过 30 秒的操作需告知用户] → **逻辑漏洞**：AI 缺乏硬件上下文，无法预判 `npm install` 跑 20 秒还是 40 秒，此规则只会导致 AI 瞎猜时间或频繁打扰用户。
*   **对ChatGPT的攻击**：[[API错误 400]...] → **服务故障**：直接崩溃，未提供任何回答。

### 任务B：承认优势

*   **Claude** 在 **“主动性光谱”（Initiative Spectrum）** 这一点上比我更好，因为它用可视化的表格清晰界定了“只读操作”与“破坏性操作”的边界，比纯文字描述更直观，有助于用户理解如何配置权限白名单。

### 任务C：自我修正

**无需修正**。

*   **理由**：我的 `CLAUDE.md` 建议中包含了具体的行动指令（如 `ls -lh` 确认大小），比 Claude 笼统的“评估可行性”更具实操性。对于 CLI 工具，明确的动作（Actionable instructions）比抽象原则更能防止 AI 卡死。我的“连续失败 3 次停止”与 Claude 的“2 次”本质相同，但我的方案中包含具体的错误分析步骤，更能解决用户提到的“盲目重试”问题。

---

### ChatGPT 对其他AI的批评

[API错误 400] {"error":{"message":"openai/gpt-5.2-thinking is not a valid model ID","code":400},"user_id":"user_36jVVLYO4xMpjfEEy5jC8GINIDi"}

---

## 第三轮：最终裁判整合

# 主编裁决报告

---

## 【任务1】质量预审

- **哪个AI的回答值得认真对待？** Claude。理由：提供了完整可复制的配置模板、主动性光谱可视化表格、以及settings.json硬性配合建议，信息密度最高。

- **哪个AI的互批最有杀伤力？** Claude。理由：对Gemini"500KB阈值过严"的攻击直击实用性痛点，一个React组件文件就可能超过此限制。

- **哪个AI在被批评后表现出真正的思考深度？** Claude。理由：承认Gemini的具体命令列举和物理屏蔽建议更优，并提出具体修正方案；而Gemini声称"无需修正"却未有效反驳Claude对500KB阈值的攻击。

---

## 【任务2】互批有效性裁决

* **[Claude]攻击[Gemini]："500KB阈值过于严苛，普通React组件就可能超过"**
  → **有效**。理由：一个带JSDoc注释的TypeScript文件轻松超过500KB，此阈值会导致AI拒绝读取正常代码文件，严重影响可用性。

* **[Claude]攻击[ChatGPT]："API错误400，未提供有效回答"**
  → **有效**。理由：事实层面完全成立，ChatGPT本轮输出为零。

* **[Gemini]攻击[Claude]："AI无法预判命令执行时间，30秒规则会导致瞎猜"**
  → **有效**。理由：Claude Code运行在用户本地环境，AI确实缺乏硬件性能上下文，`npm install`在M1 Mac和老旧Windows机器上耗时差异可达10倍，此规则不可操作。

* **[Gemini]承认[Claude]："主动性光谱表格更直观"**
  → **有效承认**。理由：可视化确实比纯文字描述更易于理解和配置。

* **[Claude]承认[Gemini]："具体禁止命令清单（top/vim/git rebase -i）更具操作性"**
  → **有效承认**。理由：明确的命令名比"交互式命令"这一抽象概念更能被AI准确执行。

* **[Claude]承认[Gemini]："ignorePatterns物理屏蔽比软性原则更可靠"**
  → **有效承认**。理由：settings.json的deny规则是硬性限制，AI无法绕过，比CLAUDE.md的软性提示更有保障。

---

## 【任务3】去伪存真

**剔除共识废话**：三者都提到"先检查再执行"、"失败后分析原因"、"复杂任务分步"——这些是常识，无信息增量。

**独特洞见**：

* **主动性光谱可视化分类**（Claude）：将操作分为"高主动/适度主动/需确认"三档，用表格呈现，比抽象原则更具可配置性。证据锚点：原文"只读操作可主动，写入操作需谨慎，破坏性操作必确认"。

* **软硬结合防护策略**（Claude+Gemini互补）：CLAUDE.md提供软性行为指导，settings.json的deny规则提供硬性物理屏蔽，二者配合使用。证据锚点：Claude原文"配合settings.json使用"，Gemini原文"物理屏蔽.env或data/*.pdf"。

* **【互批增量】具体禁止命令清单**（Gemini→Claude采纳）：`top`, `vim`, `less`, `git rebase -i`等具体命令名，比"交互式命令"更具执行力。来源：Gemini原文"禁止交互式命令"章节，Claude在自我修正中采纳。

* **Token消耗警示**（Gemini）：CLAUDE.md内容会包含在每次对话的System Prompt中，需保持精简。证据锚点：原文"虽然50行不算多...建议定期清理"。

---

## 【任务4】隐含假设审查

* **Claude的隐含假设**：AI能够通过自然语言指令准确理解并遵守"10MB"、"5个文件"、"30秒"等数值边界。
  - **部分成立**。文件大小可通过`ls -lh`验证，但"30秒"执行时间AI确实无法预判。
  - 互批中是否被有效攻击：**是**，Gemini指出"AI缺乏硬件上下文"。

* **Gemini的隐含假设**：500KB是区分"安全读取"与"危险读取"的合理阈值。
  - **不成立**。现代代码文件、日志片段、JSON配置轻松超过此限制，会导致过度保守。
  - 互批中是否被有效攻击：**是**，Claude指出"React组件就可能超过"。

* **ChatGPT的隐含假设**：N/A（API错误，无有效输出）。
  - 不成立。
  - 互批中是否被有效攻击：**是**，被两方直接指出服务故障。

---

## 【任务5】核心分歧裁决

* **分歧点**：大文件阈值应设为多少？
  - Claude立场：10MB
  - Gemini立场：500KB
  - ChatGPT立场：无
  - 互批中的交锋：Claude攻击"500KB过严，React组件就可能超过"；Gemini未有效反驳。
  - **【裁决】：Claude更有力**。理由：500KB在实际开发中过于保守，会阻碍正常代码阅读；10MB更贴近"超大文件"的实际定义（如日志、PDF、数据集），且Claude建议对超限文件用`head/tail`部分读取，保留了灵活性。

* **分歧点**：失败重试次数应为2次还是3次？
  - Claude立场：2次
  - Gemini立场：3次
  - ChatGPT立场：无
  - 互批中的交锋：无直接交锋，双方各自陈述。
  - **【裁决】：Claude更有力**。理由：用户原始问题明确提到"频繁报错"，2次阈值更保守，更符合用户诉求；且2次失败已足够排除偶发因素，3次无本质优势。

---

## 【任务6】盲点扫描

* **事实层盲点**：三者均未提及Claude Code的**上下文窗口实际大小限制**（约200K tokens），这直接影响CLAUDE.md的可用长度和大文件阈值的合理性。

* **方法层盲点**：三者均未建议**按任务类型动态调整原则**——比如代码审查任务可以更宽松，生产环境操作必须更严格。一套静态原则无法覆盖所有场景。

* **价值层盲点**：三者均回避了**效率与安全的根本权衡**——过于严格的原则会导致AI变成"每步都问"的废物，但这个权衡点在哪里，没有人给出明确判断标准。

* **【互批盲区】**：三方均未质疑**CLAUDE.md软性指令的实际约束力**——AI真的会100%遵守这些自然语言规则吗？有无实测数据支撑？这是最敏感的问题，因为如果AI经常"忘记"或"忽略"这些原则，整个讨论的前提就动摇了。

---

## 【任务7】最终结论

* **核心结论**：采用Claude的配置框架（10MB阈值、2次失败即停、主动性光谱分类），补充Gemini的具体命令清单和settings.json硬性屏蔽，形成软硬结合的防护体系。

* **关键支撑点**：
  1. 10MB阈值比500KB更实用，避免阻碍正常开发
  2. 具体禁止命令清单（`vim`, `top`, `less`, `git rebase -i`）比抽象概念更具执行力
  3. CLAUDE.md软性原则必须配合settings.json的deny规则，才能形成有效防护

* **置信度**：**中**。理由：CLAUDE.md软性指令的实际约束力缺乏实测验证，AI是否会稳定遵守这些原则存在不确定性。

---

## 【任务8】下一步行动

**B. 现在应该采取的具体行动**：

1. 将Claude的"完整配置示例"复制到项目CLAUDE.md
2. 做以下修改：
   - 删除"超过30秒的操作需告知用户"（不可操作）
   - 在"禁止操作"中增加：`vim`, `top`, `less`, `htop`, `git rebase -i`
3. 在`.claude/settings.json`中添加：
   ```json
   {
     "permissions": {
       "deny": ["Read(./*.pdf)", "Read(./logs/*)", "Read(./.env*)"]
     }
   }
   ```
4. 实际使用2周后，根据AI的实际行为迭代优化原则

---

## 第四轮：内化辅导

# 内化辅导：把分析变成你的判断力

---

## 【层次1】核心洞见萃取

💎 **洞见1：软性规则必须有硬性兜底，否则只是许愿。**

为什么重要：你想通过CLAUDE.md让AI"更智能"，但自然语言指令本质上是"建议"——AI可能遵守，也可能"忘记"。真正可靠的防护是settings.json里的deny规则，那是物理屏蔽，AI绕不过去。这个洞见适用于所有"用规则约束行为"的场景：光有软性指导不够，必须有硬性机制配合。

💎 **洞见2：抽象原则不如具体清单。**

为什么重要：写"禁止交互式命令"，AI可能不知道哪些算交互式；写"禁止vim、top、less、git rebase -i"，AI一目了然。越具体，越不会被误解。这是所有"给他人/系统下指令"的通用原则。

---

## 【层次2】思维盲区诊断

🔍 **你可能的盲区：过度信任"写清楚规则就能被遵守"**

证据：从你的问题方式推断，你把CLAUDE.md当成了"AI的操作手册"，假设写进去的原则会被稳定执行。但你没有问"这些原则AI真的会遵守吗？遵守率有多高？"——这是最敏感的前提问题。

建议：下次思考类似问题时，先问自己——**"我设计的规则，有没有被绕过或忽略的可能？如果有，我的兜底机制是什么？"**

---

## 【层次3】经验连接器

🔗 **应用场景1：当你给新员工写操作手册的时候**

可以这样用：不要只写"注意食材新鲜度"，要写"肉类超过4℃存放超过2小时必须丢弃"——具体数字比抽象原则有效。同时，冰箱温度报警器就是你的"硬性兜底"，不依赖人的自觉。

🔗 **应用场景2：当你设计厨房流程防止出错的时候**

可以这样用：与其告诉厨师"大单要小心"，不如设置规则"超过8人订单自动打印两份单据、主厨必须签字确认"。软性提醒（告诉他小心）+ 硬性机制（强制签字）配合使用。

🔗 **应用场景3：当你发现员工反复犯同一个错误的时候**

可以这样用：先问——是规则不清楚（抽象），还是规则没有强制执行机制（软性）？今天的分析告诉你：两次同样错误就该停下来找原因，而不是"再试一次看看"。

---

## 【层次4】可复用思维框架

🧰 **框架名称：「软硬兼施」防护设计法**

适用场景：当你需要设计规则来约束某个执行者（人、AI、系统）的行为时

步骤：
1. **写软性指导**——用自然语言说明"应该怎么做"（CLAUDE.md / 操作手册）
2. **列具体清单**——把抽象原则转化为具体的禁止项/允许项（命令名 / 具体动作）
3. **设硬性兜底**——找到一个执行者无法绕过的机制（settings.json deny / 物理锁 / 系统权限）
4. **定失败阈值**——明确"错几次就必须停下来"（2次 / 3次）
5. **留迭代空间**——用2周后根据实际表现调整

使用示例：设计AI配置时，CLAUDE.md是软性指导，具体命令清单是具体化，settings.json的deny是硬性兜底，2次失败即停是阈值，2周后复盘是迭代。

---

## 【层次5】刻意练习设计

📝 **今日练习：**

任务：找出你餐厅里一个"软性规则经常被忽略"的场景，用「软硬兼施」框架重新设计它。

预期时间：10分钟

完成标准：当你能够写出"软性指导是___，具体清单是___，硬性兜底是___"这三句话，说明你已经掌握了这个思维方式。

可选加餐：如果想进一步提升，问自己——"这个硬性兜底，员工有没有办法绕过？如果有，我还需要什么？"

---

## 【层次6】元认知反思引导

🪞 **反思问题：**

1. 你在日常管理中，是更习惯用"软性提醒"还是"硬性机制"？这个习惯是怎么形成的？

2. 当规则被反复违反时，你的第一反应是"再强调一次"还是"换一种约束方式"？哪种更有效？

3. 今天的分析中，Gemini的"500KB阈值"被判定为过于严格——你在制定规则时，有没有类似"过度保守反而影响效率"的情况？

---

*报告由多AI互批工作流自动生成 via OpenRouter*
